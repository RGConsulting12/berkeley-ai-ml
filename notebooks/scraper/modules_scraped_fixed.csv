Module,Learning Outcomes,Key Activities
Module 0: Program Orientation,,"
• Program Introduction
• Learning Platform Overview
• Introduce Yourself
• Program Agreement"
Module 1: Introduction to Machine Learning,"
• Identify examples of the mystery box metaphor within your industry or personal experience.
• Establish the correct ML notation and concepts.
• Determine measures of discrete vs. continuous probability functions.
• Distinguish between measures of central tendency.
• Search for two data sources online and examine their characteristics.
• Identify functions and codes related to DataFrames.
• Load data into a DataFrame using pandas.
• Analyze data using selection and statistical techniques.
• Analyze different data visualization techniques.
• Create histograms and data visualizations.","
• Videos 1.1–1.6
• Mini-Lessons 1.1–1.5
• Required Knowledge Checks 1.1–1.6
• Required Discussions 1.1–1.3
• Required Codio Activities 1.1–1.3
• Self-Study Try-It Activities 1.1 and 1.2
• Self-Study Colab Activity 1.1"
Module 2: Fundamentals of Statistics and Distribution Functions,"
• Differentiate between normal and uniform distributions.
• Evaluate measures of uniform distribution using SciPy.
• Create and interpret visual plots, including probability density functions, histograms, scatter plots, pair plots, and correlation matrices.
• Discuss applications of the central limit theorem.
• Compute the mean and variance of univariate Gaussian distributions.
• Apply the law of large numbers to a given population.
• Explain covariance and correlation in multivariate distributions.
• Plot multivariate datasets.
• Compute measures of central tendency for univariate and multivariate distributions using pandas.
• Interpret a sample covariance matrix using Python.
• Identify correlations from scatter plots and conditional probabilities.","
• Videos 2.1–2.6
• Mini-Lessons 2.1–2.3
• Required Knowledge Checks 2.1–1.5
• Required Codio Assignments 2.1–2.4
• Self-Study Discussion 2.1
• Self-Study Try-It Activities 2.1 and 2.2
• Self-Study Colab Activities 2.1–2.4"
Module 3: Introduction to Data Analysis,"
• Discuss real-world contexts for the data science lifecycle.
• Demonstrate the uses of different pandas functions.
• Manipulate data given a dataset.
• Choose appropriate visualizing functions.
• Generate visualizations using pandas, seaborn, and Plotly.
• Customize plots using externally sourced documentation.
• Use pandas.groupby to manipulate data.
• Demonstrate sorting and aggregating operations using pandas.
• Perform computations between DataFrames using set index and reset index.
• Demonstrate different indexing and filtering techniques using pandas.","
• Videos 3.1–3.10
• Mini-Lessons 3.1–3.2
• Required Knowledge Checks 3.1–3.4
• Required Discussion 3.1
• Required Codio Assignments 3.1–3.4
• Self-Study Try-It Activity 3.1
• Self-Study Colab Activities 3.1–3.3"
Module 4: Fundamentals of Data Analysis,"
• Demonstrate pandas.merge to join datasets.
• Use pandas.merge to join with multiple fields using multiple variables in pandas.
• Perform merge operations on datasets.
• Use different plotting techniques in Seaborn and Plotly with pandas DataFrame to visualize the data.
• Create a variety of plot types in pandas, Seaborn, and Plotly.
• Discuss the advantages and disadvantages of each plotting library.
• Perform string manipulation in pandas.
• Import and clean messy data from real-world datasets.","
• Videos 4.1–4.11
• Mini-Lessons 4.1–4.4
• Required Knowledge Checks 4.1–4.5
• Required Codio Assignments 4.1–4.3
• Self-Study Colab Activities 4.1-4.5"
Module 5: Practical Application 1,"
• Create a GitHub portfolio.
• Apply exploratory data analysis, plotting, statistical summarization, and data visualization skills and techniques to a machine learning problem.","
• Video 5.1
• Required Assignment 5.1
• Self-Study Try-It Activity 5.1
• Self-Study Discussion 5.1"
Module 6: Data Clustering and Principal Component Analysis (PCA),"
• Apply SVD to a specific dataset.
• Analyze the results of PCA in a specific context.
• Interpret the singular value and the results of PCA.
• Apply the k-means algorithm in Python.
• Compare the two different ways of initializing centroids (k-means++ vs. random initialization).
• Compare results of multiple clustering techniques on a given dataset.
• Interpret the results of k-means and PCA given an initial dataset.
• Evaluate various clustering algorithms by examining the clustering shapes and their ability to detect outliers in a given dataset.
• Draft a problem statement.","
• Videos 6.1–6.8
• Mini-Lessons 6.1–6.4
• Required Knowledge Checks 6.1–6.5
• Required Codio Assignments 6.1–6.4
• Self-Study Colab Activities 6.1 and 6.2"
Module 7: Linear and Multiple Regressions,"
• Differentiate between a linear and nonlinear model.
• Fit a simple linear regression model using scikit-learn and Plotly.
• Compute loss in prediction in order to minimize it.
• Compute the squared error and absolute error.
• Apply the scipy.optimize function to minimize the loss function.
• Apply multiple techniques to minimize a loss function.
• Recognize the use of mean absolute error (MAE) and mean squared error (MSE).
• Predict outcomes using a multiple linear regression model.
• Recognize ordinal, nominal, and categorical data within a dataset.","
• Videos 7.1–7.12
• Mini-Lessons 7.1–7.3
• Required Knowledge Checks 7.1–7.7
• Required Codio Assignments 7.1–7.4
• Self-Study Colab Activities 7.1–7.2"
Module 8: Feature Engineering and Overfitting,"
• Articulate model fitting for nonlinear features.
• Generate nonlinear features for use by a linear model.
• Describe the difference between inference and prediction.
• Use scikit-learn transformers for generating polynomial features and prediction.
• Demonstrate the uses of different pandas functions.
• Articulate the definitions and relationships yielded from overfitting.
• Analyze the relationship between generalization and overfitting.
• Evaluate the complexity of various pipeline models.
• Select the best model based on validation data.
• Use a validation set for model selection to avoid overfitting.
• Use a test set for final model evaluation.
• Create and evaluate a linear regression model with nonlinear features using scikit-learn.","
• Videos 8.1–8.10
• Mini-Lessons 8.1–8.5
• Required Knowledge Checks 8.1–8.7
• Required Codio Assignments 8.1–8.3
• Self-Study Colab Activities 8.1–8.4"
Module 9: Model Selection and Regularization,"
• Identify the effect of polynomial features on Multidimensional data.
• Utilize sequential feature selection to explore model complexity.
• Apply regularization to control model complexity.
• Use regularization parameter ""alpha"" in ridge regression.
• Employ StandardScalar in ridge regularization.
• Scale data using standardization to avoid over-penalizing features in a regularized model.
• Apply GridSearchCV to select the optimal value for alpha.
• Select features using Lasso regression.
• Evaluate the differences between leave-one-out cross-validation, K-fold cross-validation, and holdout cross-validation.","
• Videos 9.1–9.11
• Required Knowledge Checks 9.1–9.8
• Required Codio Assignments 9.1–9.4
• Self-Study Colab Activities 9.1–9.3
• Self-Study Try-It Activity 9.1
• Self-Study Discussion 9.1"
Module 10: Time Series Analysis and Forecasting,"
• Describe the forecasting problem.
• Use modeling in time series forecasting with the effect of autocorrelations.
• Compute the sample autocorrelation and partial autocorrelation functions for a time series.
• Construct a model using classical time series decomposition.
• Differentiate between key characteristics of the autoregressive model and moving average model.
• Use the ACF and PACF to select the orders of an ARMA model.
• Interpret a forecast and its uncertainty.
• Determine the invertibility and stationarity of ARMA model and use ACF and PACF to select the order of ARMA model.","
• Videos 10.1–10.13
• Mini-Lessons 10.1 and 10.2
• Required Knowledge Checks 10.1–10.4
• Required Codio Assignments 10.1–10.4
• Self-Study Colab Activities 10.1–10.3"
Module 11: Practical Application 2,"
• Apply the CRISP-DM framework to a business problem.","
• Videos 11.1 and 11.2
• Required Assignment 11.1"
Module 12: Classification and k-Nearest Neighbors,"
• Explain the concept of classification with an email spam detection example.
• Train a nearest neighbor classifier using cross-validation.
• Use k to minimize misclassification error.
• Use cross-validation to pick hyperparameters that optimize the metric of your choosing.
• Describe the effect on threshold and choice of k using the predict_proba function in scikit-learn.
• Create a visualization of KNN decision boundaries as a function of k and threshold.
• Assess the trade-offs between classifier metrics.
• Compute the real value output by using a regression function with KNN.
• Compare the accuracy and interpretability of a properly trained linear regression and a KNN regression model.","
• Videos 12.1–12.10
• Mini-Lessons 12.1–12.3
• Required Knowledge Checks 12.1–12.5
• Required Codio Assignments 12.1–12.4
• Self-Study Colab Activities 12.1–12.3"
Module 13: Logistic Regression,"
• Analyze the characteristics and advantages of logistic regression.
• Use the scikit-learn framework to solve a basic logistic regression problem.
• Utilize logistic regression for business decision-making.
• Practice illustrating logistic regression as an optimization problem to determine the coefficients to minimize cross-entropy.
• Implement strategies to visualize decision boundaries for two variables.
• Evaluate the cross-entropy for a range of parameters.
• Apply logistic regression to generate multiclass outputs.
• Use L1 regularization to select features.
• Assess multiple models using performance metrics.","
• Videos 13.1–13.7
• Mini-Lesson 13.1
• Required Knowledge Checks 13.1–13.4
• Required Codio Assignments 13.1–13.3
• Self-Study Colab Activities 13.1–13.4"
Module 14: Decision Trees,"
• Identify the correct statements regarding decision trees and their outputs.
• Build a decision tree manually.
• Articulate the correct inputs for building decision trees using scikit-learn and visualizing them using Graphiz.
• Train a decision tree model with desired hyperparameters using scikit-learn.
• Visualize a decision tree.
• Evaluate decision tree splits.
• Evaluate overfitting of decision trees.
• Measure the impurity of a decision tree using entropy.
• Compare the performance of different grid search algorithms.
• Implement the decision tree algorithm.","
• Videos 14.1–14.11
• Mini-Lessons 14.1–14.5
• Required Knowledge Checks 14.1–14.4
• Required Codio Assignments 14.1–14.3
• Required Discussion 14.1
• Required Try-It Activity 14.2
• Self-Study Colab Activities 14.1–14.3
• Self-Study Try-It Activity 14.1"
Module 15: Gradient Descent and Optimization,"
• Compute the approximate value of a function using its derivative.
• Identify the basics of gradient descent and the impact of learning rate on convergence.
• Compute x and/or y for each iteration of gradient descent.
• Optimize a single-parameter linear regression model from scratch.
• Recognize convex one-dimensional and two-dimensional functions.
• Compute the gradient of a two-dimensional function.
• Measure the impurity of a decision tree using entropy.
• Use gradient descent to optimize a nonlinear two-dimensional regression model.
• Use stochastic gradient descent to optimize a nonlinear two-dimensional regression model.
• Compare the convergence behavior of gradient descent with stochastic gradient descent.
• Articulate the impact of stochastic gradient on bias and variance.","
• Videos 15.1–15.15
• Required Knowledge Checks 15.1–15.6
• Required Codio Assignments 15.1–15.4
• Self-Study Colab Activities 15.1–15.4"
Module 16: Classifying Nonlinear Features,"
• Identify nonlinear features in a dataset.
• Compare classification models to assess boundary definitions.
• Apply kernels to logistic regression models to automatically build nonlinear boundaries.
• Compare large- and small-margin classifiers.
• Calculate the maximum margin given a dataset.
• Create maximum margin classifier visualizations in scikit-learn.
• Articulate the working of the kernel functions in SVM using scikit-learn.
• Tune kernel and regularization parameters given a dataset.
• Discuss the results and trade-offs of various techniques.
• Refine your problem statement to include a research question, expected data sources and structure, expected results and techniques.","
• Videos 16.1–16.6
• Mini-Lesson 16.1
• Required Knowledge Checks 16.1–16.4
• Required Codio Assignments 16.1 and 16.2
• Required Discussion 16.1
• Required Capstone Assignment 16.1
• Self-Study Colab Activities 16.1–16.6"
Module 17: Practical Application 3,"
• Apply various classification methods to a business problem.
• Compare the results of k-nearest neighbors, logistic regression, decision trees, and support vector machines.","
• Videos 17.1 and 17.2
• Required Assignment 17.1"
Module 18: Natural Language Processing (NLP),"
• Identify the similarities and differences between text and numerical data.
• Convert text data to numerical data using NLTK.
• Tokenize blocks of text.
• Decide what features to extract from a text for a particular classification purpose.
• Implement feature extraction using NLTK.
• Use Bag-of-Words and TF-IDF algorithms to convert text data to numerical representation.
• Classify text data using Bag-of-Words, TF-IDF, and logistic regression algorithms.
• Compare the results of classification on text data using several models.
• Apply the naïve Bayes classifier.","
• Videos 18.1–18.6
• Mini-Lessons 18.1–18.7
• Required Knowledge Checks 18.1–18.5
• Required Codio Assignments 18.1–18.3
• Self-Study Colab Activities 18.1–18.3
• Self-Study Try-It Activity 18.1"
Module 19: Recommendation Systems,"
• Compute missing ratings from a rating dataset.
• Evaluate the trade-off between the number of factors and model performance.
• Calculate users' predictions using linear regression.
• Utilize collaborative filtering to understand users' predictions.
• Implement the Simon Funk SVD gradient descent algorithm for collaborative filtering.
• Use the SURPRISE library to build and analyze recommender systems on real datasets.
• Articulate the significance of a hybrid recommendation system.
• Determine why a surprise recommendation may occur on a recommendation system.","
• Videos 19.1–19.9
• Mini-Lessons 19.1–19.4
• Required Knowledge Checks 19.1–19.6
• Required Codio Assignments 19.1–19.3
• Required Discussion 19.1
• Self-Study Colab Activities 19.1–19.3
• Self-Study Discussion 19.1"
Module 20: Ensemble Techniques,"
• Relate the concepts of bias and variance to real-world examples.
• Employ the concept of aggregating predictors for bagging in ensemble model.
• Build a metamodel for classification and regression problems.
• Evaluate the performance of various metamodels.
• Implement bootstrapping on a dataset.
• Implement bagging on a metamodel.
• Apply out-of-bag evaluation in scikit-learn.
• Articulate the key concepts and parameters of the Random Forest algorithm in scikit-learn.
• Design random forests for classification and regression problems.
• Implement the AdaBoost algorithm.
• Compare the AdaBoost algorithm with gradient boosted trees.
• Perform a deep analysis of your identified problem in order to develop an executive brief detailing your technical findings.","
• Videos 20.1–20.9
• Mini-Lessons 20.1
• Required Knowledge Checks 20.1–20.6
• Required Try-It Activity 20.1
• Required Codio Assignments 20.1–20.3
• Self-Study Colab Activities 20.1–20.3"
Module 21: Deep Neural Networks (Part 1),"
• Articulate the basics and evolution of neural networks.
• Compute the output of a neural network given parameters and data.
• Train a simple neural network.
• Apply the basics of Keras for developing machine learning models.
• Use Keras to create, compile, fit, and evaluate a model.
• Select the appropriate output layer and loss function for multiclass classification.
• Adjust hyperparameters and model architecture to maximize model generalizability.","
• Videos 21.1–21.9
• Mini-Lessons 21.1 and 21.2
• Required Knowledge Checks 21.1–21.4
• Required Codio Assignments 21.1–21.3
• Self-Study Colab Activities 21.1–21.6"
Module 22: Deep Neural Networks (Part 2),"
• Articulate the basics of a CNN and its different layers.
• Process images in preparation for training a neural network.
• Train a neural network to recognize items and images.
• Use a pretrained network to enhance model performance.
• Interpret a neural network model.
• Compare an LSTM network to time series analysis.
• Train an LSTM network for time series analysis.
• Apply neural network techniques to a linear regression problem.
• Apply AI/ML techniques to a specific field you are interested in.","
• Videos 22.1–22.7
• Mini-Lessons 22.1–22.3
• Required Knowledge Checks 22.1–22.3
• Required Codio Assignments 22.1–22.5
• Self-Study Discussion 22.1
• Self-Study Try-It Activities 22.1–22.2"
Module 23: Generative AI,"
• Identify the limitations of generative techniques.
• Distinguish between the learning techniques of Gen AI.
• Configure a diffusion model to generate personalized AI images.
• Test different Gen AI models to compare similarities and differences.
• Generate a narrative using AI text generators in order to effectively evaluate data patterns.
• Calculate the similarity between sentences using transformers.
• Evaluate the effectiveness of Gen AI application examples.
• Identify current business applications of Gen AI technologies in finance, education, or healthcare.
• Generate a prompt for a Gen AI platform in order to analyze its effectiveness.","
• Videos 23.1–23.8
• Mini-Lessons 23.1–23.3
• Required Knowledge Checks 23.1–23.2
• Required Codio Assignment 23.1
• Required Discussion 23.1-23.2
• Required Assignment 23.1
• Self-Study Colab Activities 23.1–23.2
• Self-Study Discussions 23.1–23.2"
Module 24: Capstone,"
• Develop a nontechnical report for your comprehensive data solution that effectively addresses a real-world problem.","
• Video 24.1
• Mini-Lesson 24.1
• Required Capstone Project 24.1"
