{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing scrape_emeritus_modules.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile scrape_emeritus_modules.py\n",
    "\n",
    "import asyncio\n",
    "from playwright.async_api import async_playwright\n",
    "import pandas as pd\n",
    "\n",
    "async def scrape_emeritus_program():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        page = await browser.new_page()\n",
    "\n",
    "        await page.goto(\"https://classroom.emeritus.org/courses/12959/pages/program-outline-professional-certificate-in-machine-learning-and-artificial-intelligence?module_item_id=2328817\")\n",
    "        await page.wait_for_timeout(5000)\n",
    "\n",
    "        # TODO: Update selectors after inspecting the actual page\n",
    "        modules = await page.query_selector_all(\"h3, h4, ul\")\n",
    "\n",
    "        extracted = []\n",
    "        current_module = {\"Module\": None, \"Learning Outcomes\": \"\", \"Key Activities\": \"\"}\n",
    "\n",
    "        for el in modules:\n",
    "            tag = await el.evaluate(\"el => el.tagName\")\n",
    "            text = (await el.inner_text()).strip()\n",
    "\n",
    "            if tag == \"H3\":\n",
    "                if current_module[\"Module\"]:\n",
    "                    extracted.append(current_module)\n",
    "                current_module = {\"Module\": text, \"Learning Outcomes\": \"\", \"Key Activities\": \"\"}\n",
    "\n",
    "            elif tag == \"H4\" and \"Learning Outcomes\" in text:\n",
    "                sibling = await el.evaluate_handle(\"el => el.nextElementSibling\")\n",
    "                if sibling:\n",
    "                    current_module[\"Learning Outcomes\"] = (await sibling.inner_text()).strip()\n",
    "\n",
    "            elif tag == \"H4\" and \"Key Activities\" in text:\n",
    "                sibling = await el.evaluate_handle(\"el => el.nextElementSibling\")\n",
    "                if sibling:\n",
    "                    current_module[\"Key Activities\"] = (await sibling.inner_text()).strip()\n",
    "\n",
    "        if current_module[\"Module\"]:\n",
    "            extracted.append(current_module)\n",
    "\n",
    "        await browser.close()\n",
    "\n",
    "        df = pd.DataFrame(extracted)\n",
    "        df.to_csv(\"modules_scraped.csv\", index=False)\n",
    "        print(\"Scraping complete. Data saved to modules_scraped.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(scrape_emeritus_program())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done. Output saved to modules_scraped_clean.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"module_outline.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "modules = []\n",
    "\n",
    "for summary in soup.find_all(\"summary\"):\n",
    "    module_title = summary.get_text(strip=True)\n",
    "    container = summary.find_next_sibling(\"div\")\n",
    "\n",
    "    learning_outcomes = []\n",
    "    key_activities = []\n",
    "\n",
    "    if container:\n",
    "        # Flatten the elements inside the container for linear search\n",
    "        elements = container.find_all(recursive=True)\n",
    "\n",
    "        i = 0\n",
    "        while i < len(elements):\n",
    "            el = elements[i]\n",
    "            text = el.get_text(strip=True).lower()\n",
    "\n",
    "            if \"learning outcomes\" in text:\n",
    "                # Look ahead to next list\n",
    "                for j in range(i+1, min(i+5, len(elements))):\n",
    "                    if elements[j].name in [\"ul\", \"ol\"]:\n",
    "                        learning_outcomes = [\n",
    "                            li.get_text(strip=True) for li in elements[j].find_all(\"li\")\n",
    "                        ]\n",
    "                        break\n",
    "\n",
    "            if \"key activities\" in text:\n",
    "                for j in range(i+1, min(i+5, len(elements))):\n",
    "                    if elements[j].name == \"ul\":\n",
    "                        key_activities = [\n",
    "                            li.get_text(strip=True) for li in elements[j].find_all(\"li\")\n",
    "                        ]\n",
    "                        break\n",
    "            i += 1\n",
    "\n",
    "    modules.append({\n",
    "        \"Module\": module_title,\n",
    "        \"Learning Outcomes\": \"\\n• \" + \"\\n• \".join(learning_outcomes) if learning_outcomes else \"\",\n",
    "        \"Key Activities\": \"\\n• \" + \"\\n• \".join(key_activities) if key_activities else \"\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(modules)\n",
    "df.to_csv(\"modules_scraped_clean.csv\", index=False)\n",
    "print(\"✅ Done. Output saved to modules_scraped_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean export complete → modules_scraped_fixed.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"module_outline.html\", \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "modules = []\n",
    "\n",
    "for details in soup.find_all(\"details\"):\n",
    "    summary = details.find(\"summary\")\n",
    "    if not summary:\n",
    "        continue\n",
    "\n",
    "    # Get module title\n",
    "    title_el = summary.find(\"strong\") or summary.find(\"span\")\n",
    "    module_title = title_el.get_text(strip=True) if title_el else \"Untitled Module\"\n",
    "\n",
    "    learning_outcomes = []\n",
    "    key_activities = []\n",
    "\n",
    "    # Search for strong tags that say \"Learning Outcomes\" or \"Key Activities\"\n",
    "    strong_tags = details.find_all(\"strong\")\n",
    "    for strong in strong_tags:\n",
    "        text = strong.get_text(strip=True).lower()\n",
    "\n",
    "        if \"learning outcomes\" in text:\n",
    "            ol = strong.find_parent().find_next_sibling(\"ol\")\n",
    "            if ol:\n",
    "                learning_outcomes = [li.get_text(strip=True) for li in ol.find_all(\"li\")]\n",
    "\n",
    "        if \"key activities\" in text:\n",
    "            ul = strong.find_parent().find_next_sibling(\"div\")\n",
    "            if ul:\n",
    "                key_activities = [li.get_text(strip=True) for li in ul.find_all(\"li\")]\n",
    "\n",
    "    modules.append({\n",
    "        \"Module\": module_title,\n",
    "        \"Learning Outcomes\": \"\\n• \" + \"\\n• \".join(learning_outcomes) if learning_outcomes else \"\",\n",
    "        \"Key Activities\": \"\\n• \" + \"\\n• \".join(key_activities) if key_activities else \"\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(modules)\n",
    "df.to_csv(\"modules_scraped_fixed.csv\", index=False)\n",
    "print(\"✅ Clean export complete → modules_scraped_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
